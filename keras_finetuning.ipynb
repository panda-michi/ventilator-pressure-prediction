{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6589,"status":"ok","timestamp":1635810209809,"user":{"displayName":"panda mrt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi10Vhl_VatDLtm2ZuZxAREPYaBc_puPQ3Pkbhz7w=s64","userId":"00325656558560256374"},"user_tz":-540},"id":"fxSw3kc7qc-p"},"outputs":[],"source":["import sys, os\n","import numpy as np \n","import pandas as pd\n","import warnings\n","import pickle\n","warnings.filterwarnings(\"ignore\")\n","from sklearn.model_selection import KFold, GroupKFold\n","from sklearn.preprocessing import RobustScaler, normalize\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.optimizers.schedules import ExponentialDecay\n","from dataclasses import dataclass, asdict\n","from datetime import datetime\n","\n","workplace = '/content/drive/MyDrive/kaggle/codes/ventilator-pressure-prediction/'\n","sys.path.append(workplace)\n","from utils import save_json, load_json\n","from config import keras_model_conf\n","from functions import keras_loss_metrics"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1635810209810,"user":{"displayName":"panda mrt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi10Vhl_VatDLtm2ZuZxAREPYaBc_puPQ3Pkbhz7w=s64","userId":"00325656558560256374"},"user_tz":-540},"id":"oi0uo7NYuEkC"},"outputs":[],"source":["@dataclass\n","class train_conf():\n","    seed: int = 665\n","\n","    csv_dir: str = '/content/drive/MyDrive/kaggle/datasets/ventilator-pressure-prediction/train_v7-scaled.csv'\n","    model_dir = '/content/drive/MyDrive/kaggle/codes/ventilator-pressure-prediction/logs/dlast/good_model/'\n","\n","    # training params\n","    epoch: int = 500\n","    batch_size: int = 512\n","\n","    model_name: str = 'dlaset'\n","    model_param: keras_model_conf.dlast_conf = keras_model_conf.dlast_conf()\n","\n","    criterion: str = 'mask_mae'\n","\n","    # optimizer params\n","    lr: float = 1e-4\n","\n","    # for early stopping\n","    early_stop_patience: int = 15\n","\n","    # for scheduler\n","    factor: float = 0.75\n","    scheduler_patience: int = 7"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1635810209811,"user":{"displayName":"panda mrt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi10Vhl_VatDLtm2ZuZxAREPYaBc_puPQ3Pkbhz7w=s64","userId":"00325656558560256374"},"user_tz":-540},"id":"6vVA0jptw_fs"},"outputs":[],"source":["def load_data(df, x_col):\n","    x = df[x_col].values.astype(np.float32).reshape(-1, 80, len(x_col))\n","    x_col += ['pressure']\n","    y = df[x_col].values.astype(np.float32).reshape(-1, 80, len(x_col))\n","\n","    return x, y"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":34706,"status":"ok","timestamp":1635810245141,"user":{"displayName":"panda mrt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi10Vhl_VatDLtm2ZuZxAREPYaBc_puPQ3Pkbhz7w=s64","userId":"00325656558560256374"},"user_tz":-540},"id":"7lmaA8sqC8qg"},"outputs":[],"source":["cfg = train_conf()\n","df = pd.read_csv(cfg.csv_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16719239,"status":"ok","timestamp":1635855375297,"user":{"displayName":"panda mrt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi10Vhl_VatDLtm2ZuZxAREPYaBc_puPQ3Pkbhz7w=s64","userId":"00325656558560256374"},"user_tz":-540},"id":"cswaWwltsyi6","outputId":"fbe1591b-0c3e-4e77-a999-beefb64a8909"},"outputs":[],"source":["now = datetime.now().strftime(\"%m%d%H%M%S\")\n","out = f'{workplace}logs/finetune-{cfg.model_name}/{now}/'\n","os.makedirs(out, exist_ok=True)\n","\n","save_json(asdict(cfg), out + 'param.json')\n","\n","# x_col = ['u_in', 'u_out','time_step','u_in_cumsum','u_in_cummean','area','cross',\n","#          'cross2','R_cate','C_cate','breath_time','u_in_lag_1','u_in_lag_2','u_in_lag_3',\n","#          'u_in_lag_4','u_in_time1','u_in_time2','u_in_time3','u_in_time4','u_out_lag_1','u_out_lag_2','u_out_lag_3','u_out_lag_4'] \n","\n","x_col = ['time_step', 'u_in', 'u_out', 'cross', 'cross2', 'area',\n","       'time_step_cumsum', 'u_in_cumsum', 'u_in_lag1', 'u_out_lag1',\n","       'u_in_lag_back1', 'u_out_lag_back1', 'u_in_lag2', 'u_out_lag2',\n","       'u_in_lag_back2', 'u_out_lag_back2', 'u_in_lag3', 'u_out_lag3',\n","       'u_in_lag_back3', 'u_out_lag_back3', 'u_in_lag4', 'u_out_lag4',\n","       'u_in_lag_back4', 'u_out_lag_back4', 'breath_id__u_in__max',\n","       'breath_id__u_in__mean', 'breath_id__u_in__diffmax',\n","       'breath_id__u_in__diffmean', 'u_in_diff1', 'u_out_diff1', 'u_in_diff2',\n","       'u_out_diff2', 'u_in_diff3', 'u_out_diff3', 'u_in_diff4', 'u_out_diff4',\n","       'u_in_cummean', 'breath_id__u_in_lag', 'breath_id__u_in_lag2',\n","       'time_step_diff', 'ewm_u_in_mean', '15_in_sum', '15_in_min',\n","       '15_in_max', '15_in_mean', 'u_in_lagback_diff1', 'u_out_lagback_diff1',\n","       'u_in_lagback_diff2', 'u_out_lagback_diff2', 'R_20', 'R_5', 'R_50',\n","       'C_10', 'C_20', 'C_50', 'R__C_20__10', 'R__C_20__20', 'R__C_20__50',\n","       'R__C_50__10', 'R__C_50__20', 'R__C_50__50', 'R__C_5__10', 'R__C_5__20',\n","       'R__C_5__50']\n","\n","X, Y = load_data(df, x_col)\n","\n","pickle.dump(x_col, open(out + 'x_col.pkl', 'wb'))\n","\n","gpu_strategy = tf.distribute.get_strategy()\n","with gpu_strategy.scope():\n","    kf = KFold(n_splits=10, shuffle=True)\n","\n","    for i, (tidx, vidx) in enumerate(kf.split(X, Y)):\n","        print('###', i, '###')\n","\n","        tidx = pickle.load(open(f'{cfg.model_dir}train_idx_{i}.pkl', 'rb')) \n","        vidx = pickle.load(open(f'{cfg.model_dir}valid_idx_{i}.pkl', 'rb')) \n","\n","        X_train, X_valid = X[tidx], X[vidx]\n","        Y_train, Y_valid = Y[tidx], Y[vidx]\n","\n","        pickle.dump(tidx, open(f'{out}train_idx_{i}.pkl', 'wb'))\n","        pickle.dump(vidx, open(f'{out}valid_idx_{i}.pkl', 'wb'))\n","\n","        model = keras.models.load_model(f'{cfg.model_dir}model-{i}')\n","        optimizer = keras.optimizers.Adam(learning_rate = cfg.lr)\n","        model.compile(optimizer=optimizer, loss=keras_loss_metrics.mask_mae)\n","\n","        callbacks = []\n","\n","        callbacks.append(\n","            ReduceLROnPlateau(\n","                monitor = \"val_loss\",\n","                factor = cfg.factor,\n","                verbose = 1,\n","                patience = cfg.scheduler_patience))\n","        \n","        callbacks.append(\n","            EarlyStopping(\n","                monitor = \"val_loss\",\n","                patience = cfg.early_stop_patience,\n","                verbose =1,\n","                mode = \"min\",\n","                restore_best_weights = True))\n","\n","        model.fit(X_train, Y_train, validation_data=(X_valid, Y_valid), epochs=cfg.epoch, batch_size=cfg.batch_size, callbacks=callbacks) \n","        save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n","        model.save(f'{out}model-{i}', options=save_locally)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOWPHWOYaYSIIQiV5Ldo5x6","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1_VJp4zxTLrw0ZOcqcIXy3F2bgdbvTPli","name":"keras_finetuning.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
