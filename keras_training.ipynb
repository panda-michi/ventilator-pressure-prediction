{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"keras_training.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"fxSw3kc7qc-p","executionInfo":{"status":"ok","timestamp":1637551648957,"user_tz":-540,"elapsed":2537,"user":{"displayName":"panda mrt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi10Vhl_VatDLtm2ZuZxAREPYaBc_puPQ3Pkbhz7w=s64","userId":"00325656558560256374"}}},"source":["import sys, os\n","import numpy as np \n","import pandas as pd\n","import warnings\n","import pickle\n","warnings.filterwarnings(\"ignore\")\n","from sklearn.model_selection import KFold, GroupKFold\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.optimizers.schedules import ExponentialDecay\n","from dataclasses import dataclass, asdict\n","from datetime import datetime\n","\n","workplace = '/content/drive/MyDrive/kaggle/codes/ventilator-pressure-prediction/'\n","sys.path.append(workplace)\n","from functions import keras_loss_metrics\n","from models.keras_lstm import load_bidLSTM, load_dlast\n","from config import keras_model_conf\n","from utils import save_json, load_json"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"bszz4VKhjahI"},"source":["_supported_model = {\n","\t'bidLSTM': load_bidLSTM,\n","\t'dlast': load_dlast\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oi0uo7NYuEkC"},"source":["@dataclass\n","class train_conf():\n","    seed: int = 963\n","\n","    csv_dir: str = '/content/drive/MyDrive/kaggle/datasets/ventilator-pressure-prediction/train_v7-scaled.csv'\n","\n","    # training params\n","    epoch: int = 500\n","    batch_size: int = 512\n","\n","    model_name: str = 'dlast'\n","    model_param: keras_model_conf.dlast_conf = keras_model_conf.dlast_conf()\n","\n","    criterion: str = 'mask_mae'\n","\n","    # optimizer params\n","    lr: float = 1e-3\n","\n","    # for early stopping\n","    early_stop_patience: int = 30\n","\n","    # for scheduler\n","    factor: float = 0.5\n","    scheduler_patience: int = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6vVA0jptw_fs"},"source":["def load_data(df, x_col):\n","    x = df[x_col].values.astype(np.float32).reshape(-1, 80, len(x_col))\n","    x_col += ['pressure']\n","    y = df[x_col].values.astype(np.float32).reshape(-1, 80, len(x_col))\n","\n","    return x, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wJPa-gFKGqDq"},"source":["cfg = train_conf()\n","df = pd.read_csv(cfg.csv_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cswaWwltsyi6"},"source":["now = datetime.now().strftime(\"%m%d%H%M%S\")\n","out = f'{workplace}logs/{cfg.model_name}/{now}/'\n","os.makedirs(out, exist_ok=True)\n","\n","save_json(asdict(cfg), out + 'param.json')\n","\n","tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n","tpu_strategy = tf.distribute.TPUStrategy(tpu)\n","\n","x_col = ['time_step', 'u_in', 'u_out', 'cross', 'cross2', 'area',\n","       'time_step_cumsum', 'u_in_cumsum', 'u_in_lag1', 'u_out_lag1',\n","       'u_in_lag_back1', 'u_out_lag_back1', 'u_in_lag2', 'u_out_lag2',\n","       'u_in_lag_back2', 'u_out_lag_back2', 'u_in_lag3', 'u_out_lag3',\n","       'u_in_lag_back3', 'u_out_lag_back3', 'u_in_lag4', 'u_out_lag4',\n","       'u_in_lag_back4', 'u_out_lag_back4', 'breath_id__u_in__max',\n","       'breath_id__u_in__mean', 'breath_id__u_in__diffmax',\n","       'breath_id__u_in__diffmean', 'u_in_diff1', 'u_out_diff1', 'u_in_diff2',\n","       'u_out_diff2', 'u_in_diff3', 'u_out_diff3', 'u_in_diff4', 'u_out_diff4',\n","       'u_in_cummean', 'breath_id__u_in_lag', 'breath_id__u_in_lag2',\n","       'time_step_diff', 'ewm_u_in_mean', '15_in_sum', '15_in_min',\n","       '15_in_max', '15_in_mean', 'u_in_lagback_diff1', 'u_out_lagback_diff1',\n","       'u_in_lagback_diff2', 'u_out_lagback_diff2', 'R_20', 'R_5', 'R_50',\n","       'C_10', 'C_20', 'C_50', 'R__C_20__10', 'R__C_20__20', 'R__C_20__50',\n","       'R__C_50__10', 'R__C_50__20', 'R__C_50__50', 'R__C_5__10', 'R__C_5__20',\n","       'R__C_5__50']\n","\n","X, Y = load_data(df, x_col)\n","\n","pickle.dump(x_col, open(out + 'x_col.pkl', 'wb'))\n","\n","with tpu_strategy.scope():\n","    kf = KFold(n_splits=10, shuffle=True)\n","\n","    for i, (tidx, vidx) in enumerate(kf.split(X, Y)):\n","        print('###', i, '###')\n","\n","        X_train, X_valid = X[tidx], X[vidx]\n","        Y_train, Y_valid = Y[tidx], Y[vidx]\n","\n","        pickle.dump(tidx, open(f'{out}train_idx_{i}.pkl', 'wb'))\n","        pickle.dump(vidx, open(f'{out}valid_idx_{i}.pkl', 'wb'))\n","\n","        model = _supported_model[cfg.model_name](**asdict(cfg.model_param))\n","        optimizer = keras.optimizers.Adam(learning_rate = cfg.lr)\n","        model.compile(optimizer=optimizer, loss=keras_loss_metrics.mask_mae)\n","\n","        callbacks = []\n","\n","        callbacks.append(\n","            ReduceLROnPlateau(\n","                monitor = \"val_loss\",\n","                factor = cfg.factor,\n","                verbose = 1,\n","                patience = cfg.scheduler_patience))\n","        \n","        callbacks.append(\n","            EarlyStopping(\n","                monitor = \"val_loss\",\n","                patience = cfg.early_stop_patience,\n","                verbose =1,\n","                mode = \"min\",\n","                restore_best_weights = True))\n","\n","        model.fit(X_train, Y_train, validation_data=(X_valid, Y_valid), epochs=cfg.epoch, batch_size=cfg.batch_size, callbacks=callbacks) \n","        save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n","        model.save(f'{out}model-{i}', options=save_locally)"],"execution_count":null,"outputs":[]}]}